{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElBenjaM/Whisper/blob/main/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****IMPORTANTE*** tener activada la **Aceleración por hardware** con GPU en `\"≡\"(en smartphone) > \"Entorno de ejecución\" > \"Cambiar tipo de entorno de ejecución\"`."
      ],
      "metadata": {
        "id": "MJwupoMetAOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ⚙️ Descargar librerias para el funcionamiento del codigo (Obligatorio)\n",
        "#@markdown Todo es 100% online, ya que el codigo funciona en un \"PC\" prestado por Google, lo único que se les puede descargar en su PC o Teléfono es la transcripción e interpretación de los Audios/Videos si apretan la sección \"Descargar transcripción en archivo Word\" o \"Descargar Interpretación de GTP-3\"\n",
        "print(\"Descargando...\")\n",
        "!pip install -q git+https://github.com/openai/whisper.git \n",
        "!pip install openai > /dev/null\n",
        "!pip install pytube > /dev/null\n",
        "!pip install python-docx > /dev/null\n",
        "import docx\n",
        "import whisper\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"audios\"):\n",
        "  os.makedirs(\"audios\")\n",
        "\n",
        "if not os.path.exists(\"videos\"):\n",
        "  os.makedirs(\"videos\")    \n",
        "\n",
        "#@title Configuaracion para grabar audio\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "  var my_div = document.createElement(\"DIV\");\n",
        "  var my_p = document.createElement(\"P\");\n",
        "  var my_btn = document.createElement(\"BUTTON\");\n",
        "  var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "  my_btn.appendChild(t);\n",
        "  //my_p.appendChild(my_btn);\n",
        "  my_div.appendChild(my_btn);\n",
        "  document.body.appendChild(my_div);\n",
        "\n",
        "  var base64data = 0;\n",
        "  var reader;\n",
        "  var recorder, gumStream;\n",
        "  var recordButton = my_btn;\n",
        "\n",
        "  var handleSuccess = function(stream) {\n",
        "    gumStream = stream;\n",
        "    var options = {\n",
        "      //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "      mimeType : 'audio/webm;codecs=opus'\n",
        "      //mimeType : 'audio/webm;codecs=pcm'\n",
        "    };            \n",
        "    //recorder = new MediaRecorder(stream, options);\n",
        "    recorder = new MediaRecorder(stream);\n",
        "    recorder.ondataavailable = function(e) {            \n",
        "      var url = URL.createObjectURL(e.data);\n",
        "      var preview = document.createElement('audio');\n",
        "      preview.controls = true;\n",
        "      preview.src = url;\n",
        "      document.body.appendChild(preview);\n",
        "\n",
        "      reader = new FileReader();\n",
        "      reader.readAsDataURL(e.data); \n",
        "      reader.onloadend = function() {\n",
        "        base64data = reader.result;\n",
        "        //console.log(\"Inside FileReader:\" + base64data);\n",
        "      }\n",
        "    };\n",
        "    recorder.start();\n",
        "  };\n",
        "\n",
        "  recordButton.innerText = \"Grabando... presione para detener\";\n",
        "\n",
        "  navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "  function toggleRecording() {\n",
        "    if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      //recordButton.innerText = \"Guardando Audio...\"\n",
        "      recordButton.parentNode.removeChild(recordButton);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // https://stackoverflow.com/a/951057\n",
        "  function sleep(ms) {\n",
        "    return new Promise(resolve => setTimeout(resolve, ms));\n",
        "  }\n",
        "\n",
        "  var data = new Promise(resolve=>{\n",
        "  //recordButton.addEventListener(\"click\", toggleRecording);\n",
        "  recordButton.onclick = ()=>{\n",
        "  toggleRecording()\n",
        "\n",
        "  sleep(2000).then(() => {\n",
        "    // wait 2000ms for the data to be available...\n",
        "    // ideally this should use something like await...\n",
        "    //console.log(\"Inside data:\" + base64data)\n",
        "    resolve(base64data.toString())\n",
        "\n",
        "  });\n",
        "\n",
        "  }\n",
        "  });\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr\n",
        "clear_output()\n",
        "print(\"Descargado!\")   "
      ],
      "metadata": {
        "id": "KhNdagc48h0m",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despliega el módulo que te interese usar y ve apretando los ▶️ de arriba hacia abajo\"."
      ],
      "metadata": {
        "id": "c-GmSSc5X5hT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj6sKxnyo0G_"
      },
      "source": [
        "#1-Codigo para subir Audios/Videos y transcribirlos "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dale al play para comenzar a subir tu Audio o Video\n",
        "from google.colab import files\n",
        "import os \n",
        "\n",
        "# Carga el archivo de audio\n",
        "audioo = files.upload()\n",
        "\n",
        "# Accede al primer elemento del diccionario (el nombre del archivo)\n",
        "Nombre_audio = list(audioo.keys())[0]"
      ],
      "metadata": {
        "id": "ycMHlcdkr2JY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Elegir Modelo \n",
        "#@markdown Entre más pesado el modelo, saldrá de mejor calidad la transcripción pero se demorará más tiempo, se recomienda usar el modelo \"medium\" para la mayoria de casos. Si al usar \"medium\" faltan palabras o transcribe mal usar \"large\"(el resto mala calidad).\n",
        "\n",
        "# Mostramos un mensaje de que se está realizando la transcripción\n",
        "print(\"Transcribiendo...\")\n",
        "\n",
        "import whisper\n",
        "modelo_trascripcion = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "model = whisper.load_model(modelo_trascripcion)\n",
        "audio = whisper.load_audio(f\"{Nombre_audio}\")\n",
        "\n",
        "# Convertimos el audio a espectrograma mel-log\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# Realizamos la transcripción\n",
        "result = model.transcribe(audio, without_timestamps=True)\n",
        "\n",
        "# Mostramos el texto transcrito por pantalla\n",
        "print(result[\"text\"])\n",
        "\n",
        "#------------------------------------------------------------"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xVsz9MKXr8yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descargar transcripción en archivo Word\n",
        "import docx\n",
        "from google.colab import files\n",
        "# Creamos un nuevo documento de Word\n",
        "document = docx.Document()\n",
        "\n",
        "# Añadimos el contenido de la transcripción al documento de Word\n",
        "document.add_paragraph(f\"▼ Transcripción de {Nombre_audio}\")\n",
        "document.add_paragraph(result[\"text\"])\n",
        "nombr3 = \"Transcripcion_\"\n",
        "\n",
        "# Guardamos el documento de Word en la carpeta base de Google Colab\n",
        "document.save(f\"{nombr3+Nombre_audio}.docx\")\n",
        "\n",
        "# Descargamos el documento de Word\n",
        "files.download(f\"{nombr3+Nombre_audio}.docx\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cbFI_HvksxIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Interactuar con GTP-3/ Experimentro extra\n",
        "#@markdown *Puedes interactuar con GTP-3 para preguntarle cosas sobre tu transcripción (puede dar fallar o inventar información)\n",
        "\n",
        "#@markdown *Si la transcripción del audio es muy larga puede presentar fallas (intentar igualmente)\n",
        "\n",
        "#@markdown *Si se te ocurre alguna pregunta interesante, avísame para agregarla o dime si alguna de las que ya están no sirven para nada :U\n",
        "\n",
        "#codigo para usar GTP-3\n",
        "Pregunta_gtp3 = \"que le pasa al protagonista de la siguiente transcripcion?\" #@param [\"de que se trata la siguiente Transcripcion?\", \"resume la siguiente Transcripcion\", \"de que se trata la siguiente cancion?\", \"que le pasa al protagonista de la siguiente transcripcion?\",\"crea una fabula a partir de la siguiente transcripcion\"]\n",
        "idioma_transcripcion=\"Espanol\"#@param [\"Espanol\",\"Ingles\", \"otro\"]\n",
        "\n",
        "if idioma_transcripcion == \"Espanol\":\n",
        "    idiomaa = \": \"\n",
        "elif idioma_transcripcion == \"Ingles\"or\"otro\":\n",
        "    idiomaa = \"(en español): \"\n",
        "\n",
        "\n",
        "# Luego, definimos nuestra cadena de texto\n",
        "text = Pregunta_gtp3+idiomaa+result[\"text\"]\n",
        "\n",
        "# Calculamos el número de tokens en la cadena de texto\n",
        "num_tokens = len(text.split())*2.25\n",
        "\n",
        "numero_tokens= int(4096-num_tokens)\n",
        "\n",
        "if numero_tokens > 1024:\n",
        "  numero_tokens=1024\n",
        "  prompt = Pregunta_gtp3+idiomaa+result[\"text\"] \n",
        "  completion = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=numero_tokens, n=1,stop=None,temperature=0.7)\n",
        "  print(\"GTP-3:\"+completion.choices[0].text)\n",
        "\n",
        "  gtp1 = (completion.choices[0].text)  \n",
        "\n",
        "elif numero_tokens < 1025 and numero_tokens > 1:\n",
        "  prompt = Pregunta_gtp3+idiomaa+result[\"text\"] \n",
        "  completion = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=numero_tokens, n=1,stop=None,temperature=0.7)\n",
        "  print(\"GTP-3:\"+completion.choices[0].text)\n",
        "\n",
        "  gtp1 = (completion.choices[0].text)  \n",
        "\n",
        "elif numero_tokens< 2:\n",
        "  print(\"Transcripción muy larga, no se puede usar GTP-3\") \n",
        "  gtp1=\"no se pudo usar GTP-3\"   \n",
        "  "
      ],
      "metadata": {
        "cellView": "form",
        "id": "Km-2v935c6JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descargar Interpretación de GTP-3\n",
        "from google.colab import files\n",
        "# Creamos un nuevo documento de Word\n",
        "document = docx.Document()\n",
        "\n",
        "# Añadimos el contenido de la transcripción al documento de Word\n",
        "document.add_paragraph(f\"▼ Interpretación GTP-3\")\n",
        "document.add_paragraph(gtp1)\n",
        "\n",
        "nombre = \"Interpretacion_Gtp3_\"\n",
        "\n",
        "# Guardamos el documento de Word en la carpeta base de Google Colab\n",
        "document.save(f\"{nombre + Nombre_audio}.docx\")\n",
        "\n",
        "# Descargamos el documento de Word\n",
        "files.download(f\"{nombre +Nombre_audio}.docx\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8j_Hbosy4foD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-Codigo para grabar audios y transcribirlos "
      ],
      "metadata": {
        "id": "8fhHTm3jXx2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Grabar Audio\n",
        "# Importa la librería y los módulos de ipywidgets\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button, HBox, VBox, Text\n",
        "\n",
        "# Crea una caja de texto para ingresar el nombre del audio\n",
        "audio_input = Text(placeholder='¿Cómo quieres que se llame tu audio?')\n",
        "\n",
        "# Crea un botón para descargar el audio\n",
        "download_button = Button(description='Grabar Audio')\n",
        "\n",
        "\n",
        "# Define la función que se ejecutará al hacer clic en el botón\n",
        "def on_button_clicked(b):\n",
        "    clear_output() \n",
        "    # Obtiene el nombre del audio de la caja de texto\n",
        "    audio_nombre = audio_input.value +\".wav\"\n",
        "\n",
        "    # Grabamos el audio\n",
        "    audio, sr = get_audio()\n",
        "\n",
        "    # Almacenamos el audio en un archivo .wav\n",
        "    write(\"audios/\" + audio_nombre, sr, audio)\n",
        "    print(\"  \"+audio_nombre + \" se ha guardado\")\n",
        "\n",
        "# Asigna la función al evento \"on_click\" del botón\n",
        "download_button.on_click(on_button_clicked)\n",
        "\n",
        "# Muestra la caja de texto y el botón en el notebook\n",
        "display(HBox([audio_input, download_button]))"
      ],
      "metadata": {
        "id": "hhIRjs6xb7H0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Elegir Modelo \n",
        "#@markdown Entre más pesado el modelo, saldrá de mejor calidad la transcripción pero se demorará más tiempo, se recomienda usar el modelo \"medium\" para la mayoria de casos. Si al usar \"medium\" faltan palabras o transcribe mal usar \"large\"(el resto mala calidad).\n",
        "\n",
        "import os\n",
        "\n",
        "# Obtiene la lista de archivos en la carpeta \"audios\"\n",
        "files = os.listdir(\"audios\")\n",
        "\n",
        "# Ordena los archivos por fecha de modificación\n",
        "files.sort(key=lambda x: os.path.getmtime(\"audios/\" + x))\n",
        "\n",
        "# Obtiene el nombre del último archivo\n",
        "nombre_audio2 = files[-1]\n",
        "\n",
        "# Mostramos un mensaje de que se está realizando la transcripción\n",
        "print(\"Transcribiendo...\")\n",
        "\n",
        "import whisper\n",
        "modelo_trascripcion = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "model = whisper.load_model(modelo_trascripcion)\n",
        "audio = whisper.load_audio(f\"audios/{nombre_audio2}\")\n",
        "\n",
        "# Convertimos el audio a espectrograma mel-log\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# Realizamos la transcripción\n",
        "result2 = model.transcribe(audio, without_timestamps=True)\n",
        "\n",
        "# Mostramos el texto transcrito por pantalla\n",
        "print(result2[\"text\"])\n",
        "\n",
        "#------------------------------------------------------------"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ofO7uwKOZNu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descargar transcripción en archivo Word\n",
        "import docx\n",
        "from google.colab import files\n",
        "# Creamos un nuevo documento de Word\n",
        "document = docx.Document()\n",
        "\n",
        "# Añadimos el contenido de la transcripción al documento de Word\n",
        "document.add_paragraph(f\"▼ Transcripción de {nombre_audio2}\")\n",
        "document.add_paragraph(result2[\"text\"])\n",
        "\n",
        "nombr3 = \"Transcripcion_\"\n",
        "\n",
        "# Guardamos el documento de Word en la carpeta base de Google Colab\n",
        "document.save(f\"{nombr3+nombre_audio2}.docx\")\n",
        "\n",
        "# Descargamos el documento de Word\n",
        "files.download(f\"{nombr3+nombre_audio2}.docx\")"
      ],
      "metadata": {
        "id": "gYvskETjZT5A",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Interactuar con GTP-3/ Experimentro extra\n",
        "#@markdown *Puedes interactuar con GTP-3 para preguntarle cosas sobre tu transcripción (puede dar fallar o inventar información)\n",
        "\n",
        "#@markdown *Si la transcripción del audio es muy larga puede presentar fallas (intentar igualmente)\n",
        "\n",
        "#@markdown *Si se te ocurre alguna pregunta interesante, avísame para agregarla o dime si alguna de las que ya están no sirven para nada :U\n",
        "\n",
        "#codigo para usar GTP-3\n",
        "Pregunta_gtp3 = \"crea una fabula a partir de la siguiente transcripcion\" #@param [\"de que se trata la siguiente Transcripcion?\", \"resume la siguiente Transcripcion\", \"de que se trata la siguiente cancion?\", \"que le pasa al protagonista de la siguiente transcripcion?\",\"crea una fabula a partir de la siguiente transcripcion\"]\n",
        "idioma_transcripcion=\"Espanol\"#@param [\"Espanol\",\"Ingles\", \"otro\"]\n",
        "\n",
        "if idioma_transcripcion == \"Espanol\":\n",
        "    idiomaa = \": \"\n",
        "elif idioma_transcripcion == \"Ingles\"or\"otro\":\n",
        "    idiomaa = \"(en español): \"\n",
        "\n",
        "\n",
        "# Luego, definimos nuestra cadena de texto\n",
        "text = Pregunta_gtp3+idiomaa+result2[\"text\"]\n",
        "\n",
        "# Calculamos el número de tokens en la cadena de texto\n",
        "num_tokens = len(text.split())*2.25\n",
        "\n",
        "numero_tokens= int(4096-num_tokens)\n",
        "\n",
        "if numero_tokens > 1024:\n",
        "  numero_tokens=1024\n",
        "  prompt = Pregunta_gtp3+idiomaa+result2[\"text\"] \n",
        "  completion = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=numero_tokens, n=1,stop=None,temperature=0.7)\n",
        "  print(\"GTP-3:\"+completion.choices[0].text)\n",
        "\n",
        "  gtp2 = (completion.choices[0].text)  \n",
        "\n",
        "elif numero_tokens < 1025 and numero_tokens > 1:\n",
        "  prompt = Pregunta_gtp3+idiomaa+result2[\"text\"] \n",
        "  completion = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=numero_tokens, n=1,stop=None,temperature=0.7)\n",
        "  print(\"GTP-3:\"+completion.choices[0].text)\n",
        "\n",
        "  gtp2 = (completion.choices[0].text)  \n",
        "\n",
        "elif numero_tokens< 2:\n",
        "  print(\"Transcripción muy larga, no se puede usar GTP-3\") \n",
        "  gtp2=\"no se pudo usar GTP-3\"   \n",
        "  "
      ],
      "metadata": {
        "cellView": "form",
        "id": "74k40HHwDIfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descargar Interpretación de GTP-3\n",
        "from google.colab import files\n",
        "# Creamos un nuevo documento de Word\n",
        "document = docx.Document()\n",
        "\n",
        "# Añadimos el contenido de la transcripción al documento de Word\n",
        "document.add_paragraph(f\"▼ Interpretación GTP-3\")\n",
        "document.add_paragraph(gtp2)\n",
        "\n",
        "nombre = \"Interpretacion_Gtp3_\"\n",
        "\n",
        "# Guardamos el documento de Word en la carpeta base de Google Colab\n",
        "document.save(f\"{nombre + nombre_audio2}.docx\")\n",
        "\n",
        "# Descargamos el documento de Word\n",
        "files.download(f\"{nombre +nombre_audio2}.docx\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wQ3Xvvvh0Hwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3-Codigo transcribir videos de Youtube "
      ],
      "metadata": {
        "id": "7u-DkHbW3FWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ingresar URL del video\n",
        "\n",
        "# Importa la librería y los módulos de ipywidgets\n",
        "import pytube\n",
        "from ipywidgets import Button, HBox, VBox, Text\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Crea una caja de texto para ingresar la URL del video\n",
        "url_input = Text(placeholder='Ingresa la URL del video de YouTube')\n",
        "\n",
        "# Crea un botón para descargar el video\n",
        "download_button = Button(description='Descargar video')\n",
        "\n",
        "# Define la función que se ejecutará al hacer clic en el botón\n",
        "def on_button_clicked(b):\n",
        "    # Obtiene la URL del video de la caja de texto\n",
        "    url = url_input.value\n",
        "\n",
        "    # Crea un objeto \"Video\" utilizando la URL del video\n",
        "    video = pytube.YouTube(url)\n",
        "    print(\"Descargando.....(Espera mensaje de confirmación)\")\n",
        "    # Obtiene el primer stream de video disponible en calidad máxima\n",
        "    stream = video.streams.get_highest_resolution()\n",
        "\n",
        "    # Descarga el stream a la carpeta \"videos\"\n",
        "    stream.download(\"videos\")\n",
        "    clear_output()\n",
        "    # Muestra un mensaje de éxito\n",
        "    print(\"El video se ha descargado con éxito\")\n",
        "\n",
        "# Asigna la función al evento \"on_click\" del botón\n",
        "download_button.on_click(on_button_clicked)\n",
        "\n",
        "# Muestra la caja de texto y el botón en el notebook\n",
        "display(HBox([url_input, download_button]))\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rQipiyYm8a32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Elegir Modelo \n",
        "#@markdown Entre más pesado el modelo, saldrá de mejor calidad la transcripción pero se demorará más tiempo, se recomienda usar el modelo \"medium\" para la mayoria de casos. Si al usar \"medium\" faltan palabras o transcribe mal usar \"large\"(el resto mala calidad).\n",
        "# Mostramos un mensaje de que se está realizando la transcripción\n",
        "import os\n",
        "\n",
        "# Obtiene la lista de archivos en la carpeta \"videos\"\n",
        "files = os.listdir(\"videos\")\n",
        "\n",
        "# Ordena la lista por fecha de modificación (del más reciente al más antiguo)\n",
        "files = sorted(files, key=lambda x: os.path.getmtime(\"videos/\"+x))\n",
        "\n",
        "# Obtiene el último archivo de la lista (el más reciente)\n",
        "nombre_audio3 = files[-1]\n",
        "\n",
        "print(\"Transcribiendo...\")\n",
        "\n",
        "import whisper\n",
        "modelo_trascripcion = \"medium\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "model = whisper.load_model(modelo_trascripcion)\n",
        "audio = whisper.load_audio(f\"videos/{nombre_audio3}\")\n",
        "\n",
        "# Convertimos el audio a espectrograma mel-log\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# Realizamos la transcripción\n",
        "result3 = model.transcribe(audio, without_timestamps=True)\n",
        "\n",
        "# Mostramos el texto transcrito por pantalla\n",
        "print(result3[\"text\"])\n",
        "\n",
        "#------------------------------------------------------------"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SIpu0FGe3rEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descargar transcripción en archivo Word\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Creamos un nuevo documento de Word\n",
        "document = docx.Document()\n",
        "\n",
        "# Añadimos el contenido de la transcripción al documento de Word\n",
        "document.add_paragraph(f\"▼ Transcripción de {nombre_audio3}\")\n",
        "document.add_paragraph(result3[\"text\"])\n",
        "\n",
        "nombr3 = \"Transcripcion_\"\n",
        "\n",
        "# Guardamos el documento de Word en la carpeta base de Google Colab\n",
        "document.save(f\"{nombr3+nombre_audio3}.docx\")\n",
        "\n",
        "# Descargamos el documento de Word\n",
        "files.download(f\"{nombr3+nombre_audio3}.docx\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vx_hu8Hc37Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Interactuar con GTP-3/ Experimentro extra\n",
        "#@markdown *Puedes interactuar con GTP-3 para preguntarle cosas sobre tu transcripción (puede dar fallar o inventar información)\n",
        "\n",
        "#@markdown *Si la transcripción del audio es muy larga puede presentar fallas (intentar igualmente)\n",
        "\n",
        "#@markdown *Si se te ocurre alguna pregunta interesante, avísame para agregarla o dime si alguna de las que ya están no sirven para nada :U\n",
        "\n",
        "#codigo para usar GTP-3\n",
        "Pregunta_gtp3 = \"de que se trata la siguiente Transcripcion?\" #@param [\"de que se trata la siguiente Transcripcion?\", \"resume la siguiente Transcripcion\", \"de que se trata la siguiente cancion?\", \"que le pasa al protagonista de la siguiente transcripcion?\",\"crea una fabula a partir de la siguiente transcripcion\"]\n",
        "idioma_transcripcion=\"Espanol\"#@param [\"Espanol\",\"Ingles\", \"otro\"]\n",
        "\n",
        "if idioma_transcripcion == \"Espanol\":\n",
        "    idiomaa = \": \"\n",
        "elif idioma_transcripcion == \"Ingles\"or\"otro\":\n",
        "    idiomaa = \"(en español): \"\n",
        "\n",
        "\n",
        "# Luego, definimos nuestra cadena de texto\n",
        "text = Pregunta_gtp3+idiomaa+result3[\"text\"]\n",
        "\n",
        "# Calculamos el número de tokens en la cadena de texto\n",
        "num_tokens = len(text.split())*2.25\n",
        "\n",
        "numero_tokens= int(4096-num_tokens)\n",
        "\n",
        "if numero_tokens > 1024:\n",
        "  numero_tokens=1024\n",
        "  prompt = Pregunta_gtp3+idiomaa+result3[\"text\"] \n",
        "  completion = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=numero_tokens, n=1,stop=None,temperature=0.7)\n",
        "  print(\"GTP-3:\"+completion.choices[0].text)\n",
        "\n",
        "  gtp3 = (completion.choices[0].text)  \n",
        "\n",
        "elif numero_tokens < 1025 and numero_tokens > 1:\n",
        "  prompt = Pregunta_gtp3+idiomaa+result3[\"text\"] \n",
        "  completion = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=numero_tokens, n=1,stop=None,temperature=0.7)\n",
        "  print(\"GTP-3:\"+completion.choices[0].text)\n",
        "\n",
        "  gtp3 = (completion.choices[0].text)  \n",
        "\n",
        "elif numero_tokens< 2:\n",
        "  print(\"Transcripción muy larga, no se puede usar GTP-3\") \n",
        "  gtp3=\"no se pudo usar GTP-3\"   \n",
        "  "
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZhjZjqae4mRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descargar Interpretación de GTP-3\n",
        "from google.colab import files\n",
        "# Creamos un nuevo documento de Word\n",
        "document = docx.Document()\n",
        "\n",
        "# Añadimos el contenido de la transcripción al documento de Word\n",
        "document.add_paragraph(f\"▼ Interpretación GTP-3\")\n",
        "document.add_paragraph(gtp3)\n",
        "\n",
        "nombre = \"Interpretacion_Gtp3_\"\n",
        "\n",
        "# Guardamos el documento de Word en la carpeta base de Google Colab\n",
        "document.save(f\"{nombre + nombre_audio3}.docx\")\n",
        "\n",
        "# Descargamos el documento de Word\n",
        "files.download(f\"{nombre +nombre_audio3}.docx\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "62pi1o_90LZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Zj6sKxnyo0G_",
        "8fhHTm3jXx2w",
        "7u-DkHbW3FWC"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
